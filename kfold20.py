# -*- coding: utf-8 -*-
"""KFold.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b_tk2QmavVfldQ9wOxMru1oeHrXjxD6j
"""

import pandas as pd
from google.colab import drive
drive.mount('/content/gdrive')
path='/content/gdrive/My Drive/new_df.csv'
Y=pd.read_csv(path, index_col='ProtocolName')

Y.drop(columns=['Unnamed: 0'], inplace=True)
Y = Y.reset_index(drop=False)
# new_df.drop(columns=['index'], inplace=True)

y = Y['ProtocolName']
x = Y.drop(columns=['ProtocolName'])

Y.head()

from sklearn.model_selection import cross_val_predict
from sklearn.svm import SVR
from sklearn.model_selection import KFold
from sklearn import metrics
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
import lightgbm as lgb
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
import csv
serial=0
acc=[]
pr=[]
re=[]
f1=[]
def Classifiers():
  #clf = {1 : KNeighborsClassifier(n_neighbors=3),
  #2 : KNeighborsClassifier(n_neighbors=5),
  #3 : KNeighborsClassifier(n_neighbors=7),
  #4 : KNeighborsClassifier(n_neighbors=9),
  #5 : KNeighborsClassifier(n_neighbors=11),
  #6 : KNeighborsClassifier(n_neighbors=13),
  #7 : KNeighborsClassifier(n_neighbors=15),
  #8 : KNeighborsClassifier(n_neighbors=17),
  #9 : KNeighborsClassifier(n_neighbors=19),
  #10 : KNeighborsClassifier(n_neighbors=21),
  #11 : KNeighborsClassifier(n_neighbors=23)
  #12 : XGBClassifier(n_estimators=2000, max_depth=4)
  #13 : XGBClassifier(n_estimators=2200, max_depth=5),
  clf = {
  1 : XGBClassifier(n_estimators=500, max_depth=3),
  2 : XGBClassifier(n_estimators=700, max_depth=4),
  3 : XGBClassifier(n_estimators=900, max_depth=5),
  4 : XGBClassifier(n_estimators=1200, max_depth=3),
  5 : XGBClassifier(n_estimators=1500, max_depth=3),
  6 : KNeighborsClassifier(n_neighbors=5),
  7 : KNeighborsClassifier(n_neighbors=7),
  8 : KNeighborsClassifier(n_neighbors=9),
  9 : KNeighborsClassifier(n_neighbors=11),
  10 : KNeighborsClassifier(n_neighbors=13),
  11 : RandomForestClassifier(n_estimators=4000, max_depth=16,n_jobs=-1),
  12 : RandomForestClassifier(n_estimators=4500, max_depth=20,n_jobs=-1),
  13 : RandomForestClassifier(n_estimators=5000, max_depth=22,n_jobs=-1),
  14 : RandomForestClassifier(n_estimators=3500, max_depth=20,n_jobs=-1),
  15 : RandomForestClassifier(n_estimators=3000, max_depth=20,n_jobs=-1),
  16 : lgb.LGBMClassifier(n_estimators=4000, max_depth=3),
  17 : lgb.LGBMClassifier(n_estimators=4500, max_depth=4),
  18 : lgb.LGBMClassifier(n_estimators=3500, max_depth=5),
  19 : lgb.LGBMClassifier(n_estimators=3000, max_depth=4),
  20 : lgb.LGBMClassifier(n_estimators=5000, max_depth=3)
  }
  return clf
y = Y['ProtocolName']
x = Y.drop(columns=['ProtocolName'])
classifier= Classifiers()
cv = KFold(n_splits=5)         
for i in range(1,21,1):
  clf = classifier[i]
  print("Classifier :", i)
  for train_index, test_index in cv.split(x):
    X_train, X_test, y_train, y_test = x.iloc[train_index],x.iloc[test_index], y.iloc[train_index], y.iloc[test_index]
    clf.fit(X_train,y_train)
    y_pred = clf.predict(X_test)
    acc.append(metrics.accuracy_score(y_test, y_pred))
    pr.append(metrics.precision_score(y_test, y_pred, average='micro'))
    re.append(metrics.recall_score(y_test, y_pred, average='micro'))
    f1.append(metrics.f1_score(y_test, y_pred, average='micro'))
  meanacc=np.mean(acc) #1
  stdacc=np.std(acc)   #2
  meanpr=np.mean(pr)   #3
  stdpr=np.std(pr)     #4
  meanre=np.mean(re)   #5
  stdre=np.std(re)     #6
  meanf1=np.mean(f1)   #7
  stdf1=np.std(f1)     #8
  r=[meanacc, stdacc, meanpr,stdpr, meanre,stdre ,meanf1, stdf1]

  with open('/content/gdrive/My Drive/Results20.csv', 'a+', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(r)
    #serial=serial + 1

import warnings
warnings.filterwarnings('ignore')

len(range(1,21,1))
